{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report for the Continuous Control Project\n",
    "\n",
    "\n",
    "## Setting up the environment and DDPG algorithm\n",
    "\n",
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ddpg_agent import Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unity environment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Reacher.app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State and action space and DDPG configuration\n",
    "\n",
    "The objective of Unity's [Reacher environment](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Learning-Environment-Examples.md#reacher) is to move the 20 double-jointed arms to reach and maintain a target location for as long as possible. \n",
    "\n",
    "**Action space:** For each of the 20 arms, the action space is a vector with four numbers, corresponding to torque applicable to two joints. Every entry in the action vector should be a number between -1 and 1.\n",
    "\n",
    "**State space:** The observation space consists of 33 variables corresponding to position, rotation, velocity, and angular velocities for each of the 20 arms.\n",
    "\n",
    "**Reward function:** The reward is given to each agent individually: A reward of +0.1 is given each step the agent's arm is in its individual target location.\n",
    "\n",
    "**DDPG structure:** Similar to Google DeepMind's paper, [\"Continuous Control with Deep Reinforcement Learning\"](https://arxiv.org/abs/1509.02971), the adopted learning algorithm is a DDPG algorithm. DDPG is a model-free policy-based reinforcement learning algorithm where agents learn by observing state spaces with no prior knowledge of the environment. Learning improves by using policy gradient optimization.\n",
    "\n",
    "DDPG is an Actor-Critic model: \n",
    "* The Actor is a policy-based algorithm with high variance, taking relatively long to converge.\n",
    "* The Critic is a value-based algorithm with high bias instead\n",
    "\n",
    "In this approach, Actor and Critic work together to reach better convergence and performance.\n",
    "\n",
    "**Actor model**\n",
    "\n",
    "Neural network with 3 fully connected layers:\n",
    "* Fully connected layer 1: with input = 33 (state spaces) and output = 400\n",
    "* Fully connected layer 2: with input = 400 and output = 300\n",
    "* Fully connected layer 3: with input = 300 and output = 4 (for each of the 4 actions)\n",
    "\n",
    "Tanh is used in the final layer that maps states to actions. Batch normalization is used for mini batch training.\n",
    "\n",
    "**Critic model**\n",
    "\n",
    "Neural network with 3 fully connected layers:\n",
    "* Fully connected layer 1: with input = 33 (state spaces) and output = 400\n",
    "* Fully connected layer 2: with input = 404 (states and actions) and output = 300\n",
    "* Fully connected layer 3: with input = 300 and output = 1 (maps states and actions to Q-values)\n",
    "\n",
    "**Parameters used in the DDPG algorithm:**\n",
    "* Replay buffer size: BUFFER_SIZE = int(1e5)\n",
    "* Minibatch size: BATCH_SIZE = 128\n",
    "* Discount factor: GAMMA = 0.99\n",
    "* Soft update of target parameters: TAU = 1e-3\n",
    "* Learning rate of the actor: LR_ACTOR = 1e-4\n",
    "* Learning rate of the critic: LR_CRITIC = 1e-3\n",
    "* L2 weight decay: WEIGHT_DECAY = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking Random Actions in the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.11399999745190144\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]        \n",
    "    \n",
    "    # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDPG training and results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor(\n",
      "  (fc1): Linear(in_features=33, out_features=400, bias=True)\n",
      "  (fc2): Linear(in_features=400, out_features=300, bias=True)\n",
      "  (fc3): Linear(in_features=300, out_features=4, bias=True)\n",
      ")\n",
      "Critic(\n",
      "  (fcs1): Linear(in_features=33, out_features=400, bias=True)\n",
      "  (fc2): Linear(in_features=404, out_features=300, bias=True)\n",
      "  (fc3): Linear(in_features=300, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "agents = Agents(state_size=state_size, \n",
    "                action_size=action_size, \n",
    "                num_agents=num_agents, \n",
    "                random_seed=0)\n",
    "print(agents.actor_local)\n",
    "print(agents.critic_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(n_episodes=2000, max_t=1000):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        state = env_info.vector_observations\n",
    "        agents.reset()\n",
    "        score = np.zeros(num_agents)\n",
    "        for t in range(max_t):\n",
    "            action = agents.act(state)\n",
    "            env_info = env.step(action)[brain_name]\n",
    "            next_state = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            agents.step(state, action, rewards, next_state, dones)\n",
    "            state = next_state\n",
    "            score += rewards\n",
    "            if np.any(dones):\n",
    "                print('\\tSteps: ', t)\n",
    "                break \n",
    "        scores_deque.append(np.mean(score))\n",
    "        scores.append(np.mean(score))\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tScore: {:.3f}'.\\\n",
    "              format(i_episode, np.mean(scores_deque), np.mean(score)), end=\"\")\n",
    "        avg_score = np.mean(scores_deque)\n",
    "        if i_episode % 20 == 0 or avg_score > 30:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, avg_score))\n",
    "            torch.save(agents.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agents.critic_local.state_dict(), 'checkpoint_critic.pth') \n",
    "            if avg_score > 30:\n",
    "                print('\\nEnvironment solved in {:d} episodes!'.format(i_episode))\n",
    "                break\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20\tAverage Score: 1.87\tScore: 4.662\n",
      "Episode 40\tAverage Score: 5.23\tScore: 9.2761\n",
      "Episode 60\tAverage Score: 8.05\tScore: 20.155\n",
      "Episode 80\tAverage Score: 11.13\tScore: 24.621\n",
      "Episode 100\tAverage Score: 14.96\tScore: 35.352\n",
      "Episode 120\tAverage Score: 21.76\tScore: 35.259\n",
      "Episode 140\tAverage Score: 26.87\tScore: 33.939\n",
      "Episode 155\tAverage Score: 30.15\tScore: 34.476\n",
      "\n",
      "Environment solved in 155 episodes!\n"
     ]
    }
   ],
   "source": [
    "scores = ddpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary and further optimization proposal\n",
    "\n",
    "By increasing the number of episodes (increasing *n_episodes* from *1000* to *2000*) and by finetuning the hyperparameters (reducing L2 weight decay to zero and reducing the actor learning rate *LR_Actor* to *1e-4*) the DDPG algorithm was eventually successful in solving the environment in 155 episodes. \n",
    "\n",
    "To further enhance the accuracy of the DDPG agents, I would recommend implementing additional optimization techniques, such as Trust Region Policy Optimization (TRPO) and Truncated Natural Policy Gradient (TNPG), as discussed in the following paper on [\"Benchmarking Deep Reinforcement Learning for Continuous Control\"](https://arxiv.org/abs/1604.06778), as well as the novel Distributed Distributional Deterministic Policy Gradients (D4PG) algorithm (discussed [here](https://openreview.net/forum?id=SyZipzbCb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
